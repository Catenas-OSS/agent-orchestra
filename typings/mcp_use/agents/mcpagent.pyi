"""
This type stub file was generated by pyright.
"""

from collections.abc import AsyncGenerator, AsyncIterator
from typing import TypeVar
from langchain.schema import BaseMessage, SystemMessage
from langchain.schema.language_model import BaseLanguageModel
from langchain_core.agents import AgentAction
from pydantic import BaseModel
from mcp_use.client import MCPClient
from mcp_use.connectors.base import BaseConnector
from ..managers.base import BaseServerManager

"""
MCP: Main integration module with customizable system prompt.

This module provides the main MCPAgent class that integrates all components
to provide a simple interface for using MCP tools with different LLMs.
"""
T = TypeVar("T", bound=BaseModel)
class MCPAgent:
    """Main class for using MCP tools with various LLM providers.

    This class provides a unified interface for using MCP tools with different LLM providers
    through LangChain's agent framework, with customizable system prompts and conversation memory.
    """
    def __init__(self, llm: BaseLanguageModel | None = ..., client: MCPClient | None = ..., connectors: list[BaseConnector] | None = ..., max_steps: int = ..., auto_initialize: bool = ..., memory_enabled: bool = ..., system_prompt: str | None = ..., system_prompt_template: str | None = ..., additional_instructions: str | None = ..., disallowed_tools: list[str] | None = ..., tools_used_names: list[str] | None = ..., use_server_manager: bool = ..., server_manager: BaseServerManager | None = ..., verbose: bool = ..., agent_id: str | None = ..., api_key: str | None = ..., base_url: str = ..., callbacks: list | None = ..., chat_id: str | None = ..., retry_on_error: bool = ..., max_retries_per_step: int = ...) -> None:
        """Initialize a new MCPAgent instance.

        Args:
            llm: The LangChain LLM to use. Not required if agent_id is provided for remote execution.
            client: The MCPClient to use. If provided, connector is ignored.
            connectors: A list of MCP connectors to use if client is not provided.
            max_steps: The maximum number of steps to take.
            auto_initialize: Whether to automatically initialize the agent when run is called.
            memory_enabled: Whether to maintain conversation history for context.
            system_prompt: Complete system prompt to use (overrides template if provided).
            system_prompt_template: Template for system prompt with {tool_descriptions} placeholder.
            additional_instructions: Extra instructions to append to the system prompt.
            disallowed_tools: List of tool names that should not be available to the agent.
            use_server_manager: Whether to use server manager mode instead of exposing all tools.
            agent_id: Remote agent ID for remote execution. If provided, creates a remote agent.
            api_key: API key for remote execution. If None, checks MCP_USE_API_KEY env var.
            base_url: Base URL for remote API calls.
            callbacks: List of LangChain callbacks to use. If None and Langfuse is configured, uses langfuse_handler.
            retry_on_error: Whether to retry tool calls that fail due to validation errors.
            max_retries_per_step: Maximum number of retries for validation errors per step.
        """
        ...
    
    async def initialize(self) -> None:
        """Initialize the MCP client and agent."""
        ...
    
    def get_conversation_history(self) -> list[BaseMessage]:
        """Get the current conversation history.

        Returns:
            The list of conversation messages.
        """
        ...
    
    def clear_conversation_history(self) -> None:
        """Clear the conversation history."""
        ...
    
    def add_to_history(self, message: BaseMessage) -> None:
        """Add a message to the conversation history.

        Args:
            message: The message to add.
        """
        ...
    
    def get_system_message(self) -> SystemMessage | None:
        """Get the current system message.

        Returns:
            The current system message, or None if not set.
        """
        ...
    
    def set_system_message(self, message: str) -> None:
        """Set a new system message.

        Args:
            message: The new system message content.
        """
        ...
    
    def set_disallowed_tools(self, disallowed_tools: list[str]) -> None:
        """Set the list of tools that should not be available to the agent.

        This will take effect the next time the agent is initialized.

        Args:
            disallowed_tools: List of tool names that should not be available.
        """
        ...
    
    def get_disallowed_tools(self) -> list[str]:
        """Get the list of tools that are not available to the agent.

        Returns:
            List of tool names that are not available.
        """
        ...
    
    async def stream(self, query: str, max_steps: int | None = ..., manage_connector: bool = ..., external_history: list[BaseMessage] | None = ..., track_execution: bool = ..., output_schema: type[T] | None = ...) -> AsyncGenerator[tuple[AgentAction, str] | str | T, None]:
        """Run the agent and yield intermediate steps as an async generator.

        Args:
            query: The query to run.
            max_steps: Optional maximum number of steps to take.
            manage_connector: Whether to handle the connector lifecycle internally.
            external_history: Optional external history to use instead of the
                internal conversation history.
            track_execution: Whether to track execution for telemetry.
            output_schema: Optional Pydantic BaseModel class for structured output.
                If provided, the agent will attempt structured output at finish points
                and continue execution if required information is missing.

        Yields:
            Intermediate steps as (AgentAction, str) tuples, followed by the final result.
            If output_schema is provided, yields structured output as instance of the schema.
        """
        ...
    
    async def run(self, query: str, max_steps: int | None = ..., manage_connector: bool = ..., external_history: list[BaseMessage] | None = ..., output_schema: type[T] | None = ...) -> str | T:
        """Run a query using the MCP tools and return the final result.

        This method uses the streaming implementation internally and returns
        the final result after consuming all intermediate steps. If output_schema
        is provided, the agent will be schema-aware and return structured output.

        Args:
            query: The query to run.
            max_steps: Optional maximum number of steps to take.
            manage_connector: Whether to handle the connector lifecycle internally.
                If True, this method will connect, initialize, and disconnect from
                the connector automatically. If False, the caller is responsible
                for managing the connector lifecycle.
            external_history: Optional external history to use instead of the
                internal conversation history.
            output_schema: Optional Pydantic BaseModel class for structured output.
                If provided, the agent will attempt to return an instance of this model.

        Returns:
            The result of running the query as a string, or if output_schema is provided,
            an instance of the specified Pydantic model.

        Example:
            ```python
            # Regular usage
            result = await agent.run("What's the weather like?")

            # Structured output usage
            from pydantic import BaseModel, Field

            class WeatherInfo(BaseModel):
                temperature: float = Field(description="Temperature in Celsius")
                condition: str = Field(description="Weather condition")

            weather: WeatherInfo = await agent.run(
                "What's the weather like?",
                output_schema=WeatherInfo
            )
            ```
        """
        ...
    
    async def stream_events(self, query: str, max_steps: int | None = ..., manage_connector: bool = ..., external_history: list[BaseMessage] | None = ...) -> AsyncIterator[str]:
        """Asynchronous streaming interface.

        Example::

            async for chunk in agent.astream("hello"):
                print(chunk, end="|", flush=True)
        """
        ...
    
    async def close(self) -> None:
        """Close the MCP connection with improved error handling."""
        ...
    


