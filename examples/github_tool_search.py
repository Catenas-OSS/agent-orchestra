#!/usr/bin/env python3
import asyncio
import os
import sys
from pathlib import Path

# Add src to path for local development
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from agent_orchestra import SidecarMCPAgent, SidecarMCPClient

load_dotenv()  # üîë Load API keys

# 1Ô∏è‚É£ Configure the GitHub MCP server
CONFIG = { # type: ignore
    "mcpServers": {
        "github": {
            "command": "npx",
            "args": ["@modelcontextprotocol/server-github@latest"],
            "env": {
                "GITHUB_TOKEN": os.getenv("GITHUB_TOKEN")
            }
        }
    }
    
}

async def main():
    # 2Ô∏è‚É£ Create MCP client and LLM
    client = SidecarMCPClient.from_dict(CONFIG) # type: ignore
    llm = ChatOpenAI(model="gpt-4o")
    
    # 3Ô∏è‚É£ Wire the LLM to the client
    agent = SidecarMCPAgent(llm=llm, client=client, max_steps=1)
    
    try:
        print("üîç Listing all available tools from GitHub MCP server...\n")
        
        # 4Ô∏è‚É£ Ask the agent to list available tools
        result = await agent.run("List all available tools and their descriptions from the GitHub MCP server") # type: ignore
        print("üìä Available GitHub MCP Tools:")
        print(result) # type: ignore
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # 5Ô∏è‚É£ Always clean up running MCP sessions
        await client.close_all_sessions() # type: ignore

if __name__ == "__main__":
    asyncio.run(main())
