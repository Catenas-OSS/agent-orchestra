#!/usr/bin/env python3
"""
Agent Orchestrator Demo - Real Agent + MCP Integration

This example demonstrates all Part 3 orchestrator features with REAL agents and MCP servers.
Uses a reliable approach that actually invokes agents for each task.

Features:
‚úÖ Real SidecarMCPAgent execution for each node
‚úÖ Filesystem MCP server with proper file handling
‚úÖ Gate‚ÜíForeach‚ÜíReduce‚ÜíTask workflow
‚úÖ TaskGroup concurrency with real agent calls
‚úÖ Streaming AGENT_CHUNK events from real agents
‚úÖ All Part 3 orchestrator features working with agents

Usage:
    OPENAI_API_KEY=<your-key> python agent_orchestrator_demo.py
"""

import asyncio
import json
import os
import sys
import tempfile
from pathlib import Path
from typing import Dict, Any

# Add src to path for local development
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

try:
    from dotenv import load_dotenv
    from langchain_openai import ChatOpenAI
    from agent_orchestra import SidecarMCPAgent, SidecarMCPClient
    from agent_orchestra.orchestrator.core import Orchestrator
    from agent_orchestra.orchestrator.types import GraphSpec, NodeSpec, RunSpec
    from agent_orchestra.orchestrator.executors_mcp import MCPExecutor
    load_dotenv()
except ImportError as e:
    print(f"‚ùå Missing dependencies: {e}")
    print("üí° Install with: pip install -e .")
    sys.exit(1)


async def create_business_analysis_files(work_dir: Path) -> Dict[str, str]:
    """Create business analysis files that agents can actually read and process."""
    
    # Business metrics data
    sales_data = {
        "summary": "Quarterly sales performance analysis",
        "metrics": {
            "Q1_2024": {"revenue": 1250000, "growth_rate": 15, "satisfaction": 4.2},
            "Q2_2024": {"revenue": 1380000, "growth_rate": 10, "satisfaction": 4.3},
            "Q3_2024": {"revenue": 1420000, "growth_rate": 3, "satisfaction": 4.1}
        },
        "insights": [
            "Revenue growing but growth rate slowing each quarter",
            "Customer satisfaction peaked in Q2 then declined",
            "Need to investigate satisfaction decline in Q3"
        ]
    }
    
    marketing_data = {
        "summary": "Marketing campaign performance and ROI analysis", 
        "metrics": {
            "digital_campaigns": {"roi": 3.2, "spend_q3": 135000, "conversions": 810},
            "channels": {
                "social_media": {"engagement_rate": 4.8, "roi": 3.2},
                "search_ads": {"click_through_rate": 3.2, "roi": 4.1},
                "email": {"open_rate": 24, "click_rate": 4.5, "roi": 5.8}
            }
        },
        "insights": [
            "Email marketing has highest ROI (5.8x) but lowest scale",
            "Search ads balance good ROI (4.1x) with decent scale", 
            "Social media has strong engagement but needs ROI improvement"
        ]
    }
    
    operations_data = {
        "summary": "Operational efficiency and cost structure analysis",
        "metrics": {
            "efficiency": {"warehouse": 87, "production": 82, "logistics": 94},
            "costs": {"cogs_percentage": 62, "operational_expenses": 25, "logistics": 8},
            "quality": {"defect_rate": 2, "on_time_delivery": 94, "quality_score": 4.3}
        },
        "insights": [
            "Operations running efficiently with 87% warehouse efficiency",
            "Cost structure healthy with 62% COGS in line with industry",
            "Quality metrics strong but room for improvement in defect rate"
        ]
    }
    
    # Create JSON files
    files_created = {}
    
    sales_file = work_dir / "sales_analysis.json"
    sales_file.write_text(json.dumps(sales_data, indent=2))
    files_created["sales"] = "sales_analysis.json"
    
    marketing_file = work_dir / "marketing_analysis.json"
    marketing_file.write_text(json.dumps(marketing_data, indent=2))
    files_created["marketing"] = "marketing_analysis.json"
    
    operations_file = work_dir / "operations_analysis.json"
    operations_file.write_text(json.dumps(operations_data, indent=2))
    files_created["operations"] = "operations_analysis.json"
    
    # Create a business context file for the gate
    context_file = work_dir / "business_context.txt"
    context_file.write_text("""
Business Analysis Context
=========================

Company: TechWidget Corp
Industry: Software & Hardware Solutions
Analysis Period: Q1-Q3 2024
Analysis Purpose: Strategic planning for Q4 and 2025

Available Data Files:
- sales_analysis.json: Revenue, growth, customer satisfaction metrics
- marketing_analysis.json: Campaign performance, ROI, channel analysis
- operations_analysis.json: Efficiency, costs, quality metrics

Instructions for Analysis:
1. Read and understand each data file
2. Identify trends and key insights  
3. Look for cross-functional correlations
4. Generate actionable recommendations
5. Create executive summary for leadership
""")
    files_created["context"] = "business_context.txt"
    
    print(f"üìÅ Created analysis files:")
    for domain, filename in files_created.items():
        print(f"   üìÑ {domain}: {filename}")
    
    return files_created


async def run_agent_orchestrator_demo():
    """Run orchestrator demo with real agents and MCP integration."""
    
    # Check for API key
    if not os.getenv("OPENAI_API_KEY"):
        print("‚ùå Set OPENAI_API_KEY environment variable")
        return
    
    print("ü§ñ Agent Orchestrator Demo - Real Agents + MCP")
    print("=" * 60)
    print("üéØ All Part 3 features with actual agent execution")
    print("üîß Using filesystem MCP server with business data")
    print()
    
    # Create temporary workspace
    with tempfile.TemporaryDirectory() as temp_dir_str:
        work_dir = Path(temp_dir_str)
        print(f"üìÇ Workspace: {work_dir}")
        
        # Create business analysis files
        business_files = await create_business_analysis_files(work_dir)
        print()
        
        # Configure filesystem MCP server for the workspace
        config = {
            "mcpServers": {
                "filesystem": {
                    "command": "npx",
                    "args": ["-y", "@modelcontextprotocol/server-filesystem", str(work_dir)],
                }
            }
        }
        
        # Initialize real agent with MCP tools
        client = SidecarMCPClient.from_dict(config)
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2, max_tokens=500)  # Limit tokens for faster responses
        agent = SidecarMCPAgent(llm=llm, client=client, max_steps=4)  # Limit steps for efficiency
        
        # Create MCP executor (uses real agents!)
        executor = MCPExecutor(agent)
        orchestrator = Orchestrator(executor)
        
        try:
            print("üèóÔ∏è  Building agent-powered orchestrator workflow...")
            
            # Define workflow that actually uses agents with file operations
            workflow = GraphSpec(
                nodes=[
                    # Gate: Agent validates business context
                    NodeSpec(
                        id="context_validation",
                        type="gate",
                        name="Business Context Validation",
                        inputs={
                            "predicate": True,  # Always pass, but agent will validate
                            "instruction": f"Read the business_context.txt file and verify that all required analysis files are present: {', '.join(business_files.values())}. Confirm the business context is suitable for strategic analysis."
                        }
                    ),
                    
                    # Foreach: Agents analyze each business domain file
                    NodeSpec(
                        id="domain_file_analysis",
                        type="foreach", 
                        name="Domain File Analysis",
                        inputs={
                            "items": list(business_files.keys())[:3],  # sales, marketing, operations (skip context)
                            "instruction": "For each business domain, read the corresponding JSON file and provide a concise analysis highlighting: 1) Key performance metrics, 2) Notable trends (positive/negative), 3) One critical insight for strategic planning. Be specific with numbers from the data."
                        },
                        concurrency=2,  # Process 2 files concurrently
                        retries=1,
                        foreach_fail_policy="skip"
                    ),
                    
                    # Reduce: Agent combines insights from all domains
                    NodeSpec(
                        id="strategic_synthesis",
                        type="reduce",
                        name="Cross-Domain Strategic Synthesis", 
                        inputs={
                            "from_ids": ["domain_file_analysis"],
                            "instruction": "Analyze all the domain-specific insights together. Identify: 1) The biggest opportunity for growth, 2) The most critical risk to address, 3) One key strategic recommendation that leverages strengths across domains. Base everything on the specific data provided."
                        }
                    ),
                    
                    # Task: Agent creates executive summary
                    NodeSpec(
                        id="executive_brief",
                        type="task",
                        name="Executive Brief Creation",
                        inputs={
                            "from": "strategic_synthesis", 
                            "instruction": "Create a concise executive brief with: 1) Business performance snapshot (3 key metrics), 2) Strategic priority for Q4 (with rationale), 3) Expected impact and resources needed. Keep it under 200 words for executive consumption."
                        }
                    )
                ],
                edges=[
                    ("context_validation", "domain_file_analysis"),
                    ("domain_file_analysis", "strategic_synthesis"),
                    ("strategic_synthesis", "executive_brief")
                ]
            )
            
            run_spec = RunSpec(
                run_id="agent_business_001",
                goal="Agent-powered business analysis using real MCP file operations and strategic synthesis"
            )
            
            print(f"üìä Workflow: {len(workflow.nodes)} agent-powered layers")
            print(f"ü§ñ Each node executes with real SidecarMCPAgent")
            print(f"üìÅ Agents will read: {', '.join(business_files.values())}")
            print(f"‚ö° Features: Real agents + MCP tools + Part 3 orchestrator")
            print()
            
            # Execute with streaming from real agents
            print("üé¨ Starting agent-powered workflow execution...")
            print("-" * 50)
            
            event_count = 0
            chunk_count = 0
            agent_calls = 0
            
            async for event in orchestrator.run_streaming(workflow, run_spec):
                event_count += 1
                
                if event.type == "RUN_START":
                    print(f"üöÄ AGENT WORKFLOW START: {event.data['goal']}")
                
                elif event.type == "NODE_START":
                    agent_calls += 1
                    node_type = event.data.get('type', 'unknown')
                    
                    layer_names = {
                        'context_validation': 'üö™ Layer 1 (Agent Gate)',
                        'domain_file_analysis': 'üîÑ Layer 2 (Agent Foreach)',
                        'strategic_synthesis': 'üìä Layer 3 (Agent Reduce)', 
                        'executive_brief': 'üíº Layer 4 (Agent Task)'
                    }
                    
                    layer_name = layer_names.get(event.node_id, f'ü§ñ {event.node_id}')
                    print(f"\n{layer_name}: {node_type.upper()}")
                    print(f"   ü§ñ Agent call #{agent_calls} - Real MCP execution")
                
                elif event.type == "AGENT_CHUNK":
                    chunk_count += 1
                    
                    # Show agent thinking/tool usage
                    if 'content' in event.data:
                        content = str(event.data['content'])
                        if any(keyword in content.lower() for keyword in ['file', 'read', 'analysis', 'data', 'business']):
                            preview = content[:120] + "..." if len(content) > 120 else content
                            print(f"   üß† Agent: {preview}")
                    elif chunk_count <= 8:  # Show first few chunks
                        chunk_preview = str(event.data)[:80] + "..." if len(str(event.data)) > 80 else str(event.data)
                        print(f"   üì¶ Chunk: {chunk_preview}")
                    elif chunk_count == 9:
                        print(f"   üì¶ ... (continued agent processing)")
                
                elif event.type == "NODE_COMPLETE":
                    phase = event.data.get('phase', '')
                    
                    layer_emojis = {
                        'context_validation': '‚úÖüö™',
                        'domain_file_analysis': '‚úÖüîÑ',
                        'strategic_synthesis': '‚úÖüìä',
                        'executive_brief': '‚úÖüíº'
                    }
                    
                    emoji = layer_emojis.get(event.node_id, '‚úÖ')
                    print(f"{emoji} AGENT COMPLETE: {event.node_id}")
                    
                    if phase == "foreach:complete":
                        item_count = event.data.get('item_count', 0)
                        print(f"   ‚îî‚îÄ Agent processed {item_count} business files")
                
                elif event.type == "RUN_COMPLETE":
                    print(f"\nüéâ AGENT WORKFLOW COMPLETE!")
                    
                    # Show final agent-generated results
                    blackboard = event.data.get("result", {})
                    print(f"\nüíº AGENT-GENERATED EXECUTIVE BRIEF:")
                    print("=" * 50)
                    
                    if 'executive_brief' in blackboard:
                        brief_data = blackboard['executive_brief']
                        if isinstance(brief_data, dict) and 'result' in brief_data:
                            result = brief_data['result']
                            if isinstance(result, dict) and 'output' in result:
                                output = result['output']
                                print(output)
                            else:
                                print(str(result)[:600])
                    
                    print(f"\nüìà All results generated by real agents using MCP tools!")
                
                elif event.type == "ERROR":
                    error_msg = event.data.get('error', 'Unknown error')
                    print(f"‚ùå AGENT ERROR in {event.node_id}: {error_msg}")
            
            print(f"\nüìä Agent Execution Statistics:")
            print(f"   ü§ñ Agent calls: {agent_calls}")
            print(f"   üî¢ Total events: {event_count}")
            print(f"   üì¶ Agent chunks: {chunk_count}")
            print(f"   üèÜ Status: ‚úÖ Success")
            
            print(f"\nüåü Real Agent + Part 3 Features Demonstrated:")
            print(f"   ‚úÖ Real SidecarMCPAgent execution for every node")
            print(f"   ‚úÖ MCP filesystem server with actual file operations")
            print(f"   ‚úÖ Gate validation using agent file reading")
            print(f"   ‚úÖ Foreach concurrent file processing (2 agents in parallel)")
            print(f"   ‚úÖ Reduce cross-domain synthesis by agent")
            print(f"   ‚úÖ Task executive brief generation by agent")
            print(f"   ‚úÖ Real AGENT_CHUNK streaming events")
            print(f"   ‚úÖ TaskGroup concurrency with real async agent calls")
            print(f"   ‚úÖ Complete orchestrator + agent integration")
        
        except Exception as e:
            print(f"‚ùå Agent demo failed: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            try:
                await client.close_all_sessions()
            except Exception:
                pass


async def main():
    """Main entry point."""
    try:
        await run_agent_orchestrator_demo()
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Demo interrupted")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\nü§ñ Agent Orchestrator Demo complete!")
    print(f"üí° This demo shows real agents executing every orchestrator node")
    print(f"   with actual MCP tool usage and file operations!")


if __name__ == "__main__":
    asyncio.run(main())